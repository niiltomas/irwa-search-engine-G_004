{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNB5qDmzWgO6","executionInfo":{"status":"ok","timestamp":1762103260553,"user_tz":-60,"elapsed":42450,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}},"outputId":"88d70957-fd39-4bfc-fa22-f660b9d3d57c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Loaded documents: 28080\n","Example fields: ['_id', 'pid', 'title', 'description', 'brand', 'category', 'sub_category', 'product_details', 'seller', 'out_of_stock', 'selling_price', 'discount', 'actual_price', 'average_rating', 'url', 'images', 'crawled_at', 'title_proc', 'description_proc']\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#Load preprocessed dataset from part 1\n","import json\n","\n","path = \"/content/drive/Shareddrives/UPF_IRWA_project/fashion_products_dataset_preprocessed.json\"\n","\n","with open(path, \"r\", encoding=\"utf-8\") as f:\n","    dataset = json.load(f)\n","\n","print(\"Loaded documents:\", len(dataset))\n","print(\"Example fields:\", list(dataset[0].keys()))\n"]},{"cell_type":"markdown","source":["# **1. Indexing**"],"metadata":{"id":"S9ypaMz3aqv3"}},{"cell_type":"markdown","source":["**1.1 Build inverted index:**"],"metadata":{"id":"OIjAsnVUa1-Q"}},{"cell_type":"code","source":["from collections import defaultdict\n","from array import array\n","import re\n","\n","def build_terms(text):\n","    \"\"\"\n","    Simple tokenizer: splits on whitespace and removes non-alphanumeric characters.\n","    Input text must be already lowercased and preprocessed.\n","    \"\"\"\n","    tokens = re.findall(r'\\b[a-z0-9]+\\b', text.lower())\n","    return tokens\n","\n","\n","def create_index(dataset):\n","    \"\"\"\n","    Build an inverted index for the fashion products dataset.\n","\n","    Arguments:\n","    dataset -- list of documents (each document = dictionary with fields like title_proc, description_proc...)\n","\n","    Returns:\n","    index -- dictionary { term: [ [doc_id, [positions]], ... ] }\n","    pid_map -- dictionary { internal_doc_id: product_title }  (to display titles later)\n","    \"\"\"\n","    index = defaultdict(list)\n","    pid_map = {}  # map internal doc ids (ints) to titles\n","\n","    for doc_id, doc in enumerate(dataset):  # numeric id for simplicity\n","        pid_map[doc_id] = doc.get('title', 'Untitled')\n","\n","        # Concatenate main searchable text fields\n","        text = \" \".join([\n","            doc.get(\"title_proc\", \"\"),\n","            doc.get(\"description_proc\", \"\"),\n","            doc.get(\"brand_proc\", \"\"),\n","            doc.get(\"category_proc\", \"\"),\n","            doc.get(\"sub_category_proc\", \"\")\n","        ])\n","\n","        terms = build_terms(text)\n","        current_page_index = {}\n","\n","        for position, term in enumerate(terms):\n","            try:\n","                # if the term is already in current page index â†’ append new position\n","                current_page_index[term][1].append(position)\n","            except:\n","                # otherwise create new posting with doc_id and position\n","                current_page_index[term] = [doc_id, array('I', [position])]\n","\n","        # merge with main index\n","        for term_page, posting_page in current_page_index.items():\n","            index[term_page].append(posting_page)\n","\n","    return index, pid_map\n","\n","\n","# --- Build the index ---\n","index, pid_map = create_index(dataset)\n","\n","print(\"Inverted index built successfully\")\n","print(\"Number of unique terms:\", len(index))\n","sample_term = list(index.keys())[0]\n","print(f\"Example term: '{sample_term}' â†’ postings: {index[sample_term][:3]}\")\n","\n","\n"],"metadata":{"id":"OnJVmctIaund","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762103263294,"user_tz":-60,"elapsed":2642,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}},"outputId":"26bbc2ea-d00d-43ab-e27b-ae35b40391a6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Inverted index built successfully\n","Number of unique terms: 5124\n","Example term: 'solid' â†’ postings: [[0, array('I', [0])], [1, array('I', [0])], [2, array('I', [0])]]\n"]}]},{"cell_type":"markdown","source":["**1.2 Propose test queries:**"],"metadata":{"id":"dm3P02xJbRaG"}},{"cell_type":"code","source":["test_queries = [\n","    \"women track pant\",\n","    \"men track pant\",\n","    \"men pack\",\n","    \"women formal shirt\",\n","    \"men slim fit formal shirt\"\n","]\n","\n","print(\" Check which queries have matching documents:\")\n","\n","for i, q in enumerate(test_queries, 1):\n","    tokens = q.lower().split()\n","    matching_docs = [\n","        doc['title'] for doc in dataset\n","        if all(token in doc['title_proc'] for token in tokens)\n","    ]\n","    print(f\"\\nQ{i}: {q}\")\n","    if matching_docs:\n","        print(f\"   {len(matching_docs)} matching documents found\")\n","        for title in matching_docs[:5]:\n","            print(\"   \", title)\n","    else:\n","        print(\"   No matching documents\")\n"],"metadata":{"id":"qD31PKEwbXkX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762103263456,"user_tz":-60,"elapsed":164,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}},"outputId":"ab7fb984-0a42-4b4f-c533-d7224ef663fd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":[" Check which queries have matching documents:\n","\n","Q1: women track pant\n","   581 matching documents found\n","    Solid Women Multicolor Track Pants\n","    Solid Women Multicolor Track Pants\n","    Solid Women Brown, Grey Track Pants\n","    Solid Women Multicolor Track Pants\n","    Solid Women Dark Blue Track Pants\n","\n","Q2: men track pant\n","   1172 matching documents found\n","    Solid Women Multicolor Track Pants\n","    Solid Men Blue Track Pants\n","    Solid Men Multicolor Track Pants\n","    Solid Women Multicolor Track Pants\n","    Solid Women Brown, Grey Track Pants\n","\n","Q3: men pack\n","   4500 matching documents found\n","    Women Self Design Ankle LengthÂ Â (Pack of 4)\n","    Solid Men Polo Neck Dark Blue, Blue T-ShirtÂ Â (Pack of 2)\n","    Solid Men Polo Neck Red, Grey T-ShirtÂ Â (Pack of 2)\n","    Solid Men Polo Neck Grey, Black T-ShirtÂ Â (Pack of 2)\n","    Solid Men Polo Neck Dark Blue, Grey T-ShirtÂ Â (Pack of 2)\n","\n","Q4: women formal shirt\n","   238 matching documents found\n","    Women Regular Fit Solid Button Down Collar Formal Shirt\n","    Women Slim Fit Solid Formal Shirt\n","    Women Regular Fit Solid Button Down Collar Formal Shirt\n","    Women Regular Fit Solid Button Down Collar Formal Shirt\n","    Women Slim Fit Self Design Cut Away Collar Formal Shirt\n","\n","Q5: men slim fit formal shirt\n","   132 matching documents found\n","    Women Slim Fit Solid Formal Shirt\n","    Women Slim Fit Self Design Cut Away Collar Formal Shirt\n","    Men Slim Fit Solid Spread Collar Formal Shirt\n","    Men Slim Fit Solid Spread Collar Formal Shirt\n","    Men Slim Fit Solid Spread Collar Formal Shirt\n"]}]},{"cell_type":"markdown","source":["**1.3 Rank your results:**"],"metadata":{"id":"mPDwSW3RbX6n"}},{"cell_type":"code","source":["import math\n","from collections import defaultdict\n","\n","#term frequency\n","def compute_tf(term, doc_id, index):\n","    \"\"\"TF = frequency of term in document / number of terms in document\"\"\"\n","    postings = index.get(term, [])\n","    freq = 0\n","    for doc, positions in postings:\n","        if doc == doc_id:\n","            freq = len(positions)\n","            break\n","    # total terms in doc (for normalization)\n","    total_terms = len(doc_texts[doc_id].split())\n","    return freq / total_terms if total_terms > 0 else 0\n","\n","\n","# IDF\n","def compute_idf(term, index, N):\n","    \"\"\"IDF = log(N / df(term))\"\"\"\n","    df = len(index.get(term, []))\n","    return math.log((N + 1) / (df + 1)) + 1   # smooth version to avoid /0\n","\n","\n","# TF-IDF\n","def compute_tfidf(query, index, N):\n","    \"\"\"\n","    Returns a dict {doc_id: tfidf_score} for all docs matching the query (AND)\n","    \"\"\"\n","    terms = query.lower().split()\n","\n","    # get candidate documents that contain ALL query terms (AND)\n","    candidate_docs = None\n","    for t in terms:\n","        docs_with_t = set([doc for doc, _ in index.get(t, [])])\n","        candidate_docs = docs_with_t if candidate_docs is None else candidate_docs & docs_with_t\n","\n","    if not candidate_docs:\n","        return {}\n","\n","    scores = defaultdict(float)\n","    for doc_id in candidate_docs:\n","        for t in terms:\n","            tf = compute_tf(t, doc_id, index)\n","            idf = compute_idf(t, index, N)\n","            scores[doc_id] += tf * idf\n","    return scores\n","\n","\n","# Rank\n","def rank_documents(query, index, N, top_k=10):\n","    scores = compute_tfidf(query, index, N)\n","    ranked_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n","    results = [(pid_map[doc_id], round(score, 4)) for doc_id, score in ranked_docs]\n","    return results\n","\n","\n","doc_texts = [\" \".join([\n","    d.get(\"title_proc\", \"\"),\n","    d.get(\"description_proc\", \"\"),\n","    d.get(\"brand_proc\", \"\"),\n","    d.get(\"category_proc\", \"\"),\n","    d.get(\"sub_category_proc\", \"\")\n","]) for d in dataset]\n","\n","N = len(dataset)\n","\n","\n","for i, q in enumerate(test_queries, 1):\n","    print(f\"\\nðŸ”¹ Query {i}: {q}\")\n","    ranked = rank_documents(q, index, N, top_k=5)\n","    if not ranked:\n","        print(\"No matching documents.\")\n","    else:\n","        for rank, (title, score) in enumerate(ranked, 1):\n","            print(f\"{rank}. {title}  |  TF-IDF: {score}\")\n"],"metadata":{"id":"7bP0b7TRbf8G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762103274367,"user_tz":-60,"elapsed":10909,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}},"outputId":"2cd225e3-7bd7-4f56-c85b-5b6874bb8e80"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ”¹ Query 1: women track pant\n","1. Solid Women Multicolor Track Pants  |  TF-IDF: 2.2847\n","2. Solid Women Multicolor Track Pants  |  TF-IDF: 2.2847\n","3. Solid Women Multicolor Track Pants  |  TF-IDF: 2.2847\n","4. Solid Women Multicolor Track Pants  |  TF-IDF: 2.2847\n","5. Solid Women Black Track Pants  |  TF-IDF: 1.8378\n","\n","ðŸ”¹ Query 2: men track pant\n","1. Solid Men Multicolor Track Pants  |  TF-IDF: 2.2909\n","2. Solid Men Multicolor Track Pants  |  TF-IDF: 2.2909\n","3. Solid Men Blue Track Pants  |  TF-IDF: 1.8327\n","4. Solid Men Green Track Pants  |  TF-IDF: 1.8327\n","5. Solid Men Multicolor Track Pants  |  TF-IDF: 1.8327\n","\n","ðŸ”¹ Query 3: men pack\n","1. Men BriefÂ Â (Pack of 12)  |  TF-IDF: 1.1269\n","2. Men BriefÂ Â (Pack of 2)  |  TF-IDF: 1.1269\n","3. Men BriefÂ Â (Pack of 5)  |  TF-IDF: 1.1269\n","4. Men BriefÂ Â (Pack of 6)  |  TF-IDF: 1.1269\n","5. Men BriefÂ Â (Pack of 4)  |  TF-IDF: 1.1269\n","\n","ðŸ”¹ Query 4: women formal shirt\n","1. Women Solid Formal Shirt  |  TF-IDF: 1.8863\n","2. Women Regular Fit Checkered Formal Shirt  |  TF-IDF: 1.2575\n","3. Women Regular Fit Solid Formal Shirt  |  TF-IDF: 1.2575\n","4. Women Slim Fit Solid Formal Shirt  |  TF-IDF: 1.2575\n","5. Women Slim Fit Solid Formal Shirt  |  TF-IDF: 1.2575\n","\n","ðŸ”¹ Query 5: men slim fit formal shirt\n","1. Men Slim Fit Solid Formal Shirt  |  TF-IDF: 2.1545\n","2. Men Slim Fit Printed Formal Shirt  |  TF-IDF: 2.1545\n","3. Men Slim Fit Checkered Formal Shirt  |  TF-IDF: 2.1545\n","4. Men Slim Fit Printed Formal Shirt  |  TF-IDF: 2.1545\n","5. Men Slim Fit Printed Formal Shirt  |  TF-IDF: 2.1545\n"]}]},{"cell_type":"markdown","source":["# **2. Evaluation**"],"metadata":{"id":"yJRwTzVZawJg"}},{"cell_type":"markdown","source":["**2.1 Implement the following evaluation metrics to assess the effectiveness of your retrieval\n","solutions. These metrics will help you measure how well your system retrieves relevant\n","documents for each query:**"],"metadata":{"id":"f9jcnj6mbhht"}},{"cell_type":"markdown","source":["i. Precision@K (P@K)"],"metadata":{"id":"aAr0l3NBbnlv"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Precision@k\n","def precision_at_k(relevant_docs, retrieved_docs, k):\n","    retrieved_k = retrieved_docs[:k]\n","    retrieved_set = set(retrieved_k)\n","    relevant_set = set(relevant_docs)\n","    return len(retrieved_set & relevant_set) / k\n","\n"],"metadata":{"id":"9hydDwO-btSd","executionInfo":{"status":"ok","timestamp":1762103274380,"user_tz":-60,"elapsed":14,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["ii. Recall@K (R@K)"],"metadata":{"id":"ZkLhveFQbt_2"}},{"cell_type":"code","source":["# Recall@K\n","\n","def recall_at_k(relevant_docs, retrieved_docs, k):\n","    retrieved_k = retrieved_docs[:k]\n","    retrieved_set = set(retrieved_k)\n","    relevant_set = set(relevant_docs)\n","    return len(retrieved_set & relevant_set) / len(relevant_set) if relevant_set else 0.0\n","\n"],"metadata":{"id":"5QoXu4uga0X5","executionInfo":{"status":"ok","timestamp":1762103274400,"user_tz":-60,"elapsed":18,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["iii. Average Precision@K (P@K)"],"metadata":{"id":"kqR-mYO1bwCf"}},{"cell_type":"code","source":["# Average Precision@K\n","def average_precision_at_k(relevant_docs, retrieved_docs, k):\n","    retrieved_k = retrieved_docs[:k]\n","    score = 0.0\n","    relevant_found = 0\n","    relevant_set = set(relevant_docs)\n","    counted = set()\n","    for i, doc in enumerate(retrieved_k, start=1):\n","        if doc in relevant_set and doc not in counted:\n","            counted.add(doc)\n","            relevant_found += 1\n","            score += relevant_found / i\n","    return score / len(relevant_set) if relevant_set else 0.0\n","\n"],"metadata":{"id":"UmFH-YIobxMZ","executionInfo":{"status":"ok","timestamp":1762103274413,"user_tz":-60,"elapsed":9,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["iv. F1-Score@K"],"metadata":{"id":"astvcHA0bxnH"}},{"cell_type":"code","source":["# F1-Score@K\n","def f1_score_at_k(relevant_docs, retrieved_docs, k):\n","    \"\"\"F1@K = 2 * (Precision@K * Recall@K) / (Precision@K + Recall@K)\"\"\"\n","    p = precision_at_k(relevant_docs, retrieved_docs, k)\n","    r = recall_at_k(relevant_docs, retrieved_docs, k)\n","    return 0.0 if (p + r) == 0 else 2 * (p * r) / (p + r)\n"],"metadata":{"id":"okC2zRwCby_K","executionInfo":{"status":"ok","timestamp":1762103274426,"user_tz":-60,"elapsed":11,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["v. Mean Average Precision (MAP)"],"metadata":{"id":"cW_5gNAVbzYX"}},{"cell_type":"code","source":["# MAP\n","def mean_average_precision(all_queries_results, all_relevants, k):\n","    ap_values = []\n","    for qid in all_queries_results:\n","        retrieved = all_queries_results[qid]\n","        relevant = all_relevants[qid]\n","        ap_values.append(average_precision_at_k(relevant, retrieved, k))\n","    return np.mean(ap_values) if ap_values else 0.0\n"],"metadata":{"id":"EB5kQKZJb0fh","executionInfo":{"status":"ok","timestamp":1762103274554,"user_tz":-60,"elapsed":126,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["vi. Mean Reciprocal Rank (MRR)"],"metadata":{"id":"xa2Q5NNgb08n"}},{"cell_type":"code","source":["# MRR\n","def mean_reciprocal_rank(all_queries_results, all_relevants):\n","    rr = []\n","    for qid in all_queries_results:\n","        retrieved = all_queries_results[qid]\n","        relevant_set = set(all_relevants[qid])\n","        for rank, doc in enumerate(retrieved, start=1):\n","            if doc in relevant_set:\n","                rr.append(1 / rank)\n","                break\n","        else:\n","            rr.append(0.0)\n","    return np.mean(rr) if rr else 0.0\n"],"metadata":{"id":"BAIbIa3Kb2CA","executionInfo":{"status":"ok","timestamp":1762103274559,"user_tz":-60,"elapsed":2,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["vii. Normalized Discounted Cumulative Gain (NDCG)"],"metadata":{"id":"g_WWDEJ8b2e_"}},{"cell_type":"code","source":["# NDCG@K\n","import math\n","\n","def ndcg_at_k(relevant_docs, retrieved_docs, k):\n","  # Remove duplicates while keeping order\n","  seen = set()\n","  unique_retrieved = []\n","  for doc in retrieved_docs:\n","    if doc not in seen:\n","        unique_retrieved.append(doc)\n","        seen.add(doc)\n","\n","  retrieved_k = unique_retrieved[:k]\n","  relevant_set = set(relevant_docs)\n","\n","\n","  dcg = 0.0\n","  for i, doc in enumerate(retrieved_k, start=1):\n","    rel_i = 1 if doc in relevant_set else 0\n","    dcg += rel_i / math.log2(i + 1)\n","\n","\n","  ideal_relevant_count = min(len(relevant_set), k)\n","  idcg = sum(1 / math.log2(i + 1) for i in range(1, ideal_relevant_count + 1))\n","\n","\n","  return dcg / idcg if idcg > 0 else 0.0\n"],"metadata":{"id":"rtT8Af01b3HX","executionInfo":{"status":"ok","timestamp":1762103274563,"user_tz":-60,"elapsed":2,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# results\n","all_queries_results = {}\n","for i, q in enumerate(test_queries, 1):\n","    ranked = rank_documents(q, index, N, top_k=10)\n","    retrieved = [title for title, score in ranked]\n","    all_queries_results[f\"Q{i}\"] = retrieved\n","    #print(f\"Q{i} retrieved:\")\n","    #print(retrieved)\n","\n","\n","all_relevants = {\n","    \"Q1\": [\"Solid Women Multicolor Track Pants\",\"Solid Women Black Track Pants\"],\n","    \"Q2\": [\"Solid Men Blue Track Pants\", \"Solid Men Green Track Pants\"],\n","    \"Q3\": [\"Superhero Men Round Neck Multicolor T-Shirt  (Pack of 2)\", \"Superhero Women Round Neck Multicolor T-Shirt  (Pack of 2)\"],\n","    \"Q4\": [\"Women Solid Formal Shirt\", \"Women Slim Fit Solid Formal Shirt\"],\n","    \"Q5\": [\"Men Slim Fit Solid Formal Shirt\", \"Men Slim Fit Printed Formal Shirt\"]\n","}\n","\n","\n","#Evaluation\n","k = 5\n","for qid in all_queries_results:\n","    retrieved = all_queries_results[qid]\n","    relevant = all_relevants[qid]\n","\n","    p = precision_at_k(relevant, retrieved, k)\n","    r = recall_at_k(relevant, retrieved, k)\n","    ap = average_precision_at_k(relevant, retrieved, k)\n","    f1 = f1_score_at_k(relevant, retrieved, k)\n","    ndcg = ndcg_at_k(relevant, retrieved, k)\n","\n","    print(f\"\\n {qid}\")\n","    print(f\"Precision@{k}: {p:.3f}\")\n","    print(f\"Recall@{k}: {r:.3f}\")\n","    print(f\"AP@{k}: {ap:.3f}\")\n","    print(f\"F1@{k}: {f1:.3f}\")\n","    print(f\"NDCG@{k}: {ndcg:.3f}\")\n","\n","map_score = mean_average_precision(all_queries_results, all_relevants, k)\n","mrr_score = mean_reciprocal_rank(all_queries_results, all_relevants)\n","\n","print(\"\\n====================\")\n","print(f\"MAP@{k}: {map_score:.3f}\")\n","print(f\"MRR: {mrr_score:.3f}\")\n","print(\"====================\")\n"],"metadata":{"id":"9wHb3W51qTM3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762103284937,"user_tz":-60,"elapsed":10360,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}},"outputId":"106171e0-e070-4b16-cdc7-0673b8ac30f9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Q1\n","Precision@5: 0.400\n","Recall@5: 1.000\n","AP@5: 0.700\n","F1@5: 0.571\n","NDCG@5: 1.000\n","\n"," Q2\n","Precision@5: 0.400\n","Recall@5: 1.000\n","AP@5: 0.417\n","F1@5: 0.571\n","NDCG@5: 0.693\n","\n"," Q3\n","Precision@5: 0.000\n","Recall@5: 0.000\n","AP@5: 0.000\n","F1@5: 0.000\n","NDCG@5: 0.000\n","\n"," Q4\n","Precision@5: 0.400\n","Recall@5: 1.000\n","AP@5: 0.750\n","F1@5: 0.571\n","NDCG@5: 0.877\n","\n"," Q5\n","Precision@5: 0.400\n","Recall@5: 1.000\n","AP@5: 1.000\n","F1@5: 0.571\n","NDCG@5: 1.000\n","\n","====================\n","MAP@5: 0.573\n","MRR: 0.667\n","====================\n"]}]},{"cell_type":"markdown","source":["**2.2 Apply the evaluation metrics you have implemented to the search results and relevance judgments provided in validation_labels.csv for the predefined queries. When reporting evaluation results, provide only numeric values, rounded to three decimal places. Do not include textual explanations or additional statistics in this section.**\n","\n","  a. Query 1: women full sleeve sweatshirt cotton\n","   \n","  b. Query 2: men slim jeans blue"],"metadata":{"id":"ynNqeyTUb3fP"}},{"cell_type":"code","source":["import pandas as pd\n","\n","val_path = \"/content/drive/Shareddrives/UPF_IRWA_project/validation_labels.csv\"\n","validation = pd.read_csv(val_path)\n","\n","\n","#print(\"Validation data loaded\")\n","#print(validation.head())\n","\n","query_texts = {\n","    1: \"women full sleeve sweatshirt cotton\",\n","    2: \"men slim jeans blue\"\n","}\n","\n","queries = validation[\"query_id\"].unique()\n","results_numeric = {}\n","\n","for qid in queries:\n","    query_text = query_texts[qid]\n","    print(f\"\\n Evaluating Query ID: {qid} -> {query_text}\")\n","\n","    # Relevant docs\n","    q_data = validation[validation[\"query_id\"] == qid]\n","    relevant_docs = q_data[q_data[\"labels\"] == 1][\"pid\"].tolist()\n","\n","    ranked_results = rank_documents(query_text, index, N, top_k=k)\n","    retrieved_docs = [pid for pid, _ in ranked_results]\n","\n","    p = precision_at_k(relevant_docs, retrieved_docs, k)\n","    r = recall_at_k(relevant_docs, retrieved_docs, k)\n","    ap = average_precision_at_k(relevant_docs, retrieved_docs, k)\n","    f1 = f1_score_at_k(relevant_docs, retrieved_docs, k)\n","    ndcg = ndcg_at_k(relevant_docs, retrieved_docs, k)\n","\n","    results_numeric[qid] = {\n","        \"Precision@10\": round(p, 3),\n","        \"Recall@10\": round(r, 3),\n","        \"AP@10\": round(ap, 3),\n","        \"F1@10\": round(f1, 3),\n","        \"NDCG@10\": round(ndcg, 3)\n","    }\n","\n","# MAP and MRR\n","map_score = mean_average_precision(\n","    {qid: validation[validation[\"query_id\"] == qid][\"pid\"].tolist() for qid in queries},\n","    {qid: validation[(validation[\"query_id\"] == qid) & (validation[\"labels\"] == 1)][\"pid\"].tolist() for qid in queries},\n","    k\n",")\n","\n","mrr_score = mean_reciprocal_rank(\n","    {qid: validation[validation[\"query_id\"] == qid][\"pid\"].tolist() for qid in queries},\n","    {qid: validation[(validation[\"query_id\"] == qid) & (validation[\"labels\"] == 1)][\"pid\"].tolist() for qid in queries}\n",")\n","\n","print(\"\\n====================\")\n","for qid, vals in results_numeric.items():\n","    print(f\"Query ID: {qid}\")\n","    for metric, value in vals.items():\n","        print(f\"{metric}: {value:.3f}\")\n","print(f\"MAP@10: {map_score:.3f}\")\n","print(f\"MRR: {mrr_score:.3f}\")\n","print(\"====================\")"],"metadata":{"id":"02qsmYgGcKqK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762103285935,"user_tz":-60,"elapsed":996,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}},"outputId":"a7b8c5e8-1ed9-4900-d949-5e822de59939"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Evaluating Query ID: 1 -> women full sleeve sweatshirt cotton\n","\n"," Evaluating Query ID: 2 -> men slim jeans blue\n","\n","====================\n","Query ID: 1\n","Precision@10: 0.000\n","Recall@10: 0.000\n","AP@10: 0.000\n","F1@10: 0.000\n","NDCG@10: 0.000\n","Query ID: 2\n","Precision@10: 0.000\n","Recall@10: 0.000\n","AP@10: 0.000\n","F1@10: 0.000\n","NDCG@10: 0.000\n","MAP@10: 0.198\n","MRR: 1.000\n","====================\n"]}]},{"cell_type":"code","source":["#Testing frequency of terms of the queries in 2.2 in different docs\n","query_text = \"women full sleeve sweatshirt cotton\"\n","terms = query_text.lower().split()\n","\n","for t in terms:\n","    docs_with_term = index.get(t, [])\n","    print(f\"Term '{t}' is in {len(docs_with_term)} documents\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2r9iT8sihTeJ","executionInfo":{"status":"ok","timestamp":1762103285950,"user_tz":-60,"elapsed":12,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}},"outputId":"32b56d4f-3543-48cf-b728-d79d04b064d0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Term 'women' is in 13438 documents\n","Term 'full' is in 3547 documents\n","Term 'sleeve' is in 3 documents\n","Term 'sweatshirt' is in 1417 documents\n","Term 'cotton' is in 8315 documents\n"]}]},{"cell_type":"markdown","source":["**2.3 You will act as expert judges by establishing the ground truth for each document and query.**\n"],"metadata":{"id":"0_UlBjhvcP0V"}},{"cell_type":"markdown","source":["a. For the test queries you defined in Part 1, Step 2 during indexing, assign a binary relevance label to each document: 1 if the document is relevant to the query, or 0 if it is not."],"metadata":{"id":"ml4u8jO2cd4e"}},{"cell_type":"code","source":["import copy\n","\n","dataset_copy = copy.deepcopy(dataset)\n","\n","for doc in dataset_copy:\n","    doc['relevance'] = {}\n","    title_text = doc.get('title_proc', doc['title']).lower()\n","    for qid, query in enumerate(test_queries, 1):\n","        query_terms = query.lower().split()\n","        doc['relevance'][qid] = int(all(term in title_text for term in query_terms))\n","\n","# Example check\n","print(dataset_copy[0])\n","\n","\n","#Validation\n","# Initialize relevance field for each document\n","# for doc in dataset:\n","#     doc['relevance'] = {}  # Will store {query_id: 0 or 1}\n","\n","# print(\"Checking relevance and storing labels:\\n\")\n","\n","# for qid, query in enumerate(test_queries, 1):\n","#     query_terms = query.lower().split()\n","#     relevant_products = []\n","\n","#     for doc in dataset:\n","#         title = doc['title_proc'].lower()\n","#         # AND logic: all query terms must be in title\n","#         is_relevant = int(all(term in title for term in query_terms))\n","#         doc['relevance'][qid] = is_relevant\n","\n","#         if is_relevant:\n","#             relevant_products.append(doc['title'])\n","\n","#     # Print for checking (max 5 examples)\n","#     print(f\"Query {qid}: {query}\")\n","#     if relevant_products:\n","#         for title in relevant_products[:5]:\n","#             print(f\"  - {title}\")\n","#     else:\n","#         print(\"  No relevant products found.\")\n","#     print()"],"metadata":{"id":"AVoRYVJUcfPz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762103288312,"user_tz":-60,"elapsed":2359,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}},"outputId":"e81ffb83-8aff-4ba9-858a-f94dec576604"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["{'_id': 'fa8e22d6-c0b6-5229-bb9e-ad52eda39a0a', 'pid': 'TKPFCZ9EA7H5FYZH', 'title': 'Solid Women Multicolor Track Pants', 'description': 'Yorker trackpants made from 100% rich combed cotton giving it a rich look.Designed for Comfort,Skin friendly fabric,itch-free waistband & great for all year round use Proudly made in India', 'brand': 'York', 'category': 'Clothing and Accessories', 'sub_category': 'Bottomwear', 'product_details': [{'Style Code': '1005COMBO2'}, {'Closure': 'Elastic'}, {'Pockets': 'Side Pockets'}, {'Fabric': 'Cotton Blend'}, {'Pattern': 'Solid'}, {'Color': 'Multicolor'}], 'seller': 'Shyam Enterprises', 'out_of_stock': False, 'selling_price': '921', 'discount': '69% off', 'actual_price': '2,999', 'average_rating': '3.9', 'url': 'https://www.flipkart.com/yorker-solid-men-multicolor-track-pants/p/itmd2c76aadce459?pid=TKPFCZ9EA7H5FYZH&lid=LSTTKPFCZ9EA7H5FYZHVYXWP0&marketplace=FLIPKART&srno=b_1_1&otracker=browse&fm=organic&iid=177a46eb-d053-4732-b3de-fcad6ff59cbd.TKPFCZ9EA7H5FYZH.SEARCH&ssid=utkd4t3gb40000001612415717799', 'images': ['https://rukminim1.flixcart.com/image/128/128/jr3t5e80/track-pant/z/y/n/m-1005combo2-yorker-original-imafczg3xfh5qqd4.jpeg?q=70', 'https://rukminim1.flixcart.com/image/128/128/jr58l8w0/track-pant/w/d/a/l-1005combo8-yorker-original-imafczg3pgtxgraq.jpeg?q=70'], 'crawled_at': 1612987911000, 'title_proc': 'solid women multicolor track pant', 'description_proc': 'yorker trackpant made 100 rich comb cotton give rich look.design comfort skin friendli fabric itch-fre waistband great year round use proudli made india', 'relevance': {1: 1, 2: 1, 3: 0, 4: 0, 5: 0}}\n"]}]},{"cell_type":"markdown","source":["b. Comment on each of the evaluation metrics, stating how they differ, and which\n","information gives each of them. Analyze your results."],"metadata":{"id":"ZL2z8xsGcfvu"}},{"cell_type":"code","source":[],"metadata":{"id":"90Ryl44lcg7A","executionInfo":{"status":"ok","timestamp":1762103288318,"user_tz":-60,"elapsed":4,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["c. Analyze the current search system and identify its main problems or limitations. For each issue you find, propose possible ways to resolve it. Consider aspects such as retrieval accuracy, ranking quality, handling of different field types, query formulation, and indexing strategies."],"metadata":{"id":"geEcMpDfchZu"}},{"cell_type":"code","source":[],"metadata":{"id":"GXWlrst2ciHu","executionInfo":{"status":"ok","timestamp":1762103288322,"user_tz":-60,"elapsed":1,"user":{"displayName":"NIL TOMÃ€S PLANS","userId":"04170001031122885321"}}},"execution_count":15,"outputs":[]}]}